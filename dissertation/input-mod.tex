\subsection{Input Modalities}

\subsubsection{Motion Tracking Systems}


Welch and Foxlin \cite{MT-BULLET} conducted a survey on motion tracking systems,
comparing each solution in terms of cost, precision and capacity to solve the tracking problem.
The main group of purposes for motion tracking applications was identified:
view control, navigation, object selection or manipulation, instrument tracking and avatar animation.
There are motion tracking systems available based on measurements of mechanical, inertial, acoustic, magnetic,
optical and radio frequency sensors, each approach bearing its advantages and limitations.
The most robust solution lies in combining two technologies,
such as a hybrid between inertial and acoustic sensors
-- the former providing 6 degrees of freedom data and the latter reading precise positioning for each artifact.


%\paragraph{Discussion}

One can envision the proposed solution to use motion tracking to allow users to change their
point of view in the program, navigate the scene, select and manipulate objects, a subset
of functionality identified by Welch and Foxlin.

\subsubsection{Augmented Reality versus Immersive Virtual Reality}

According to Azuma \cite{OVERVIEW-AR} Augmented Reality should be used
when the collaboration task is co-located,
when there is tangible object interaction and enhanced interaction in the real world.
Immersive Virtual Reality is preferred on scenarios with shared views and
remote collaboration.

%\TODOL{MORE CONTENT FROM THIS ARTICLE?}

%\paragraph{Discussion}
%There haven't been set any goals that force the Augmented Reality approach for such a system.
Sharing views and doing collaboration are two expected features of this system so
Virtual Reality is the choice to make. No Augmented Reality feature is found in this project.


%\TODO{issuing voice commands}
%\subsubsection{Voice Commands}
%
%\cite{SP-GEST-TTOP}